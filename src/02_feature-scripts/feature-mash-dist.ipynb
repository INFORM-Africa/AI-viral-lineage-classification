{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0e3680f-9f0b-4557-93c7-dbf2e681f99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import numba\n",
    "import argparse\n",
    "import time\n",
    "from numba import jit\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8dadf354-1623-444f-94b5-292c4a9e9875",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(f'../../data/features/MASH_replace_13.parquet', engine='pyarrow')  # You can use 'fastparquet' as the engine\n",
    "\n",
    "targets = data[\"Target\"]\n",
    "train = data[\"Train\"]\n",
    "\n",
    "pair_data = data[data[\"Train\"] == 0]\n",
    "\n",
    "data = data.drop(columns=[\"Train\", \"Target\"]).to_numpy().astype(np.float32)\n",
    "pair_data = pair_data.drop(columns=[\"Train\", \"Target\"]).to_numpy().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9761674-e2bc-4dea-b8f1-7850d94e16ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def calculate_jaccard_index(sketch1, sketch2):\n",
    "    \"\"\"\n",
    "    Efficiently calculate the Jaccard index between two sorted MinHash sketches.\n",
    "    \n",
    "    :param sketch1: First sorted MinHash sketch as a numpy array.\n",
    "    :param sketch2: Second sorted MinHash sketch as a numpy array.\n",
    "    :return: The estimated Jaccard index.\n",
    "    \"\"\"\n",
    "    shared_hashes = 0  # Intersection\n",
    "    total_hashes = 0   # Union\n",
    "    i, j = 0, 0\n",
    "    \n",
    "    while i < len(sketch1) and j < len(sketch2):\n",
    "        if sketch1[i] == sketch2[j]:\n",
    "            shared_hashes += 1\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif sketch1[i] < sketch2[j]:\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "        total_hashes += 1\n",
    "\n",
    "    # Include any remaining hashes from both sketches\n",
    "    total_hashes += len(sketch1[i:]) + len(sketch2[j:])\n",
    "\n",
    "    # Calculate the Jaccard index\n",
    "    jaccard_index = shared_hashes / total_hashes if total_hashes > 0 else 0\n",
    "    \n",
    "    return jaccard_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebbbffc6-b44f-4e81-850a-287e1c9229b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Mash distance is: 0.002593151704574231\n"
     ]
    }
   ],
   "source": [
    "def calculate_mash_distance(sketch1, sketch2, k):\n",
    "    \"\"\"\n",
    "    Calculate the Mash distance between two MinHash sketches.\n",
    "\n",
    "    :param sketch1: First MinHash sketch as a numpy array.\n",
    "    :param sketch2: Second MinHash sketch as a numpy array.\n",
    "    :param k: k-mer size used to create the MinHash sketches.\n",
    "    :return: The Mash distance.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    jaccard_estimate = calculate_jaccard_index(sketch1, sketch2)\n",
    "    # Calculate the Mash distance using the formula\n",
    "    # Guard against log(0) by maxing jaccard_estimate with a very small number\n",
    "    jaccard_estimate = max(jaccard_estimate, 1e-10)\n",
    "    mash_distance = - (1 / k) * np.log((2 * jaccard_estimate) / (1 + jaccard_estimate))\n",
    "\n",
    "    return mash_distance\n",
    "\n",
    "# Example usage:\n",
    "# Assuming we have two sketches, sketch1 and sketch2, and a k-mer size k\n",
    "sketch1 = pair_data[0]  # Replace with actual MinHash sketch values\n",
    "sketch2 = pair_data[1]  # Replace with actual MinHash sketch values\n",
    "k = 21  # Example k-mer size\n",
    "\n",
    "distance = calculate_mash_distance(sketch1, sketch2, k)\n",
    "print(f\"The Mash distance is: {distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e4dbdf3-9e3a-4852-92f3-51c36bd0199f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[###############################         ] | 78% Completed | 13m 11ss"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dask.array as da\n",
    "from dask import delayed, compute\n",
    "import numpy as np\n",
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "def calculate_distances_for_sketch(sketch1, pair_data, k):\n",
    "    \"\"\"\n",
    "    Calculate the Mash distances between a single sketch and an array of sketches.\n",
    "\n",
    "    :param sketch1: The single MinHash sketch to compare against pair_data.\n",
    "    :param pair_data: Array of MinHash sketches to compare with sketch1.\n",
    "    :param k: k-mer size used to create the MinHash sketches.\n",
    "    :return: A list of Mash distances.\n",
    "    \"\"\"\n",
    "    return [calculate_mash_distance(sketch1, sketch2, k) for sketch2 in pair_data]\n",
    "\n",
    "def calculate_distance_matrix(data, pair_data, k):\n",
    "    \"\"\"\n",
    "    Calculate a matrix of Mash distances between two arrays of sketches using Dask for parallel computation.\n",
    "\n",
    "    :param data: First array of MinHash sketches.\n",
    "    :param pair_data: Second array of MinHash sketches to which to compare the first array.\n",
    "    :param k: k-mer size used to create the MinHash sketches.\n",
    "    :return: A Dask array of Mash distances.\n",
    "    \"\"\"\n",
    "    delayed_rows = []  # Initialize outside the loop\n",
    "\n",
    "    # Create a list of delayed computations for each row\n",
    "    for sketch1 in data:\n",
    "        delayed_row = delayed(calculate_distances_for_sketch)(sketch1, pair_data, k)\n",
    "        delayed_rows.append(delayed_row)\n",
    "\n",
    "    progress_bar = ProgressBar()\n",
    "    progress_bar.register()\n",
    "\n",
    "    # Compute all rows in parallel and concatenate the results\n",
    "    with progress_bar:\n",
    "        distance_matrix = compute(*delayed_rows, scheduler='processes')\n",
    "\n",
    "    return np.vstack(distance_matrix)\n",
    "\n",
    "distance_matrix = calculate_distance_matrix(data, pair_data, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29b7ca25-8e79-41bb-9cbc-f9234d327688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, create a pandas DataFrame from the NumPy array\n",
    "distance_df = pd.DataFrame(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b20d45b3-7c5f-46ce-85c4-d897e1b07e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_df[\"Target\"] = targets.tolist()\n",
    "distance_df[\"Train\"] = train.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bef24be-3e77-4e5a-9289-66391a8166b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielvanzyl@su/CERI/lib/python3.9/site-packages/pandas/io/parquet.py:190: UserWarning: The DataFrame has column names of mixed type. They will be converted to strings and not roundtrip correctly.\n",
      "  table = self.api.Table.from_pandas(df, **from_pandas_kwargs)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] Error writing bytes to file. Detail: [errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdistance_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../data/features/mash_distance_replace_13.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpyarrow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CERI/lib/python3.9/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CERI/lib/python3.9/site-packages/pandas/core/frame.py:3101\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   3020\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3021\u001b[0m \u001b[38;5;124;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[1;32m   3022\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3097\u001b[0m \u001b[38;5;124;03m>>> content = f.read()\u001b[39;00m\n\u001b[1;32m   3098\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3099\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[0;32m-> 3101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3102\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3103\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3104\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3106\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3110\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CERI/lib/python3.9/site-packages/pandas/io/parquet.py:480\u001b[0m, in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[1;32m    478\u001b[0m path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[0;32m--> 480\u001b[0m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, io\u001b[38;5;241m.\u001b[39mBytesIO)\n",
      "File \u001b[0;32m~/CERI/lib/python3.9/site-packages/pandas/io/parquet.py:228\u001b[0m, in \u001b[0;36mPyArrowImpl.write\u001b[0;34m(self, df, path, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mwrite_to_dataset(\n\u001b[1;32m    219\u001b[0m             table,\n\u001b[1;32m    220\u001b[0m             path_or_handle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    225\u001b[0m         )\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;66;03m# write to single output file\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparquet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/CERI/lib/python3.9/site-packages/pyarrow/parquet/core.py:1908\u001b[0m, in \u001b[0;36mwrite_table\u001b[0;34m(table, where, row_group_size, version, use_dictionary, compression, write_statistics, use_deprecated_int96_timestamps, coerce_timestamps, allow_truncated_timestamps, data_page_size, flavor, filesystem, compression_level, use_byte_stream_split, column_encoding, data_page_version, use_compliant_nested_type, encryption_properties, write_batch_size, dictionary_pagesize_limit, store_schema, write_page_index, write_page_checksum, sorting_columns, **kwargs)\u001b[0m\n\u001b[1;32m   1882\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1883\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ParquetWriter(\n\u001b[1;32m   1884\u001b[0m             where, table\u001b[38;5;241m.\u001b[39mschema,\n\u001b[1;32m   1885\u001b[0m             filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1906\u001b[0m             sorting_columns\u001b[38;5;241m=\u001b[39msorting_columns,\n\u001b[1;32m   1907\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[0;32m-> 1908\u001b[0m         \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_group_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_group_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1909\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1910\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path_like(where):\n",
      "File \u001b[0;32m~/CERI/lib/python3.9/site-packages/pyarrow/parquet/core.py:1104\u001b[0m, in \u001b[0;36mParquetWriter.write_table\u001b[0;34m(self, table, row_group_size)\u001b[0m\n\u001b[1;32m   1099\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTable schema does not match schema used to create file: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1100\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtable:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m vs. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mfile:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{!s}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1101\u001b[0m            \u001b[38;5;241m.\u001b[39mformat(table\u001b[38;5;241m.\u001b[39mschema, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema))\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m-> 1104\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow_group_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_group_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/CERI/lib/python3.9/site-packages/pyarrow/_parquet.pyx:2180\u001b[0m, in \u001b[0;36mpyarrow._parquet.ParquetWriter.write_table\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/CERI/lib/python3.9/site-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] Error writing bytes to file. Detail: [errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "distance_df.to_parquet(f'../../data/features/mash_distance_replace_13.parquet', engine='pyarrow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CERI)",
   "language": "python",
   "name": "ceri"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
