{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "770dd4e3-383f-4fa0-b2f5-10e4ae9ade83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deb13ea6-7ec3-4b9a-b975-2031caea4111",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string(input_string):\n",
    "    segments = []\n",
    "    current_segment = \"\"\n",
    "\n",
    "    for char in input_string:\n",
    "        if char.isalnum():\n",
    "            current_segment += char  # Append alphanumeric characters to the current segment\n",
    "        elif char.isspace():\n",
    "            continue  # Skip whitespace characters\n",
    "        else:\n",
    "            if current_segment:\n",
    "                segments.append(current_segment)  # Add the current segment to the list\n",
    "                current_segment = \"\"\n",
    "            segments.append(char)  # Add the delimiter as a separate segment\n",
    "\n",
    "    if current_segment:\n",
    "        segments.append(current_segment)  # Add the last segment if any\n",
    "\n",
    "    return segments\n",
    "\n",
    "def split_and_replace(input_string, mapping):\n",
    "    segments = split_string(input_string)\n",
    "    i = 0\n",
    "\n",
    "    while i < len(segments):\n",
    "        segment = segments[i]\n",
    "        if segment in mapping:\n",
    "            # Replace the segment with its mapped value and split it\n",
    "            new_segments = split_string(mapping[segment])\n",
    "            segments = segments[:i] + new_segments + segments[i+1:]\n",
    "            # Do not increment i, so the loop will check the new segments on the next iteration\n",
    "        else:\n",
    "            # Only increment i if no replacement was done\n",
    "            i += 1\n",
    "\n",
    "    return segments\n",
    "\n",
    "def add_conflicts(df):\n",
    "    for i, row in df.iterrows():\n",
    "        # Find the index of the first None value\n",
    "        none_indexes = row.isnull().argmax()\n",
    "        first_none_index = none_indexes if none_indexes > 0 else len(row)\n",
    "\n",
    "        # Define the range of columns to check for duplicates\n",
    "        cols_to_check = df.columns[:first_none_index]\n",
    "\n",
    "        # Extract the values to compare from the current row\n",
    "        values_to_compare = row[cols_to_check]\n",
    "\n",
    "        # Create a mask to identify rows with identical values up to the first None\n",
    "        mask = (df[cols_to_check] == values_to_compare).all(axis=1) & (df.index != i)\n",
    "\n",
    "        # Determine if there is any conflict\n",
    "        df.loc[i, 'Conflict'] = mask.any()\n",
    "        return df\n",
    "\n",
    "def resolve_conflicts(dataframe):\n",
    "    for i, row in dataframe.iterrows():\n",
    "        # Check if the row is marked as a conflict\n",
    "        if row['Conflict']:\n",
    "            # Find the first None value and replace it with \"End\"\n",
    "            for col in dataframe.columns:\n",
    "                if pd.isnull(row[col]):\n",
    "                    dataframe.at[i, col] = \".\"\n",
    "                    break\n",
    "    return dataframe\n",
    "\n",
    "# Function to adjust values based on the depth (distance to the first None)\n",
    "def adjust_values(row):\n",
    "    # Find the index of the first None value in the row (ignoring the last three columns which are 'Values', 'Color', 'Conflict')\n",
    "    first_none_index = next((i for i, x in enumerate(row[:-10]) if x is None), len(row))\n",
    "    \n",
    "    # Adjust the 'Values' based on the depth\n",
    "    adjusted_value = row['Values'] / (first_none_index)\n",
    "    \n",
    "    return adjusted_value\n",
    "\n",
    "def encode_fullstops(strings):\n",
    "    # Initialize an empty list to hold the 1-hot encoded vector\n",
    "    encoded_vector = []\n",
    "    \n",
    "    # Iterate over each string in the input list\n",
    "    for item in strings:\n",
    "        # Append 1 to the vector if the item is a full stop, otherwise append 0\n",
    "        encoded_vector.append(0 if item == '.' else 1)\n",
    "    \n",
    "    return encoded_vector\n",
    "\n",
    "def filter_elements(original_list, encoded_vector):\n",
    "    # Ensure the two lists are of the same length\n",
    "    if len(original_list) != len(encoded_vector):\n",
    "        raise ValueError(\"Both lists must be of the same length.\")\n",
    "    \n",
    "    # Use list comprehension to filter the original list based on the encoded vector\n",
    "    filtered_list = [element for element, flag in zip(original_list, encoded_vector) if flag == 1]\n",
    "    \n",
    "    return filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5538eacf-3b8b-4bfc-9fe3-bfc989b7d19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('alias_key.json', 'r') as f:\n",
    "    mapping = json.load(f)\n",
    "\n",
    "for key, value in mapping.items():\n",
    "    if isinstance(value, list):\n",
    "        mapping[key] = '[' + ', '.join(value) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f34dd7e0-0faf-430c-85c9-a737a86b2116",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv('../04_feature-evaluation/predictions/random_forest_Testing.csv')\n",
    "predictions = predictions.drop(columns=[\"FCGR_remove_128\"])\n",
    "column_mapping = {\n",
    "    '7-mer_FFP_remove': 'FFP',\n",
    "    '7-mer_remove': 'K-mer',\n",
    "    '7-spaced_remove': 'Spaced',\n",
    "    'ACS_remove': 'ACS',\n",
    "    'DSP_replace_real': 'GSP',\n",
    "    'FCGR_remove_256': 'FCGR',\n",
    "    'Mash_distance_remove_21': 'Mash',\n",
    "    'RTD_7-mer_remove': 'RTD'\n",
    "}\n",
    "\n",
    "predictions = predictions.rename(columns=column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5097a537-dcd5-45ac-81cb-13dfdf17d255",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracies = pd.DataFrame(index=predictions['Original_Targets'].unique())\n",
    "\n",
    "# Iterate over each model column (excluding 'Original_Targets' and 'Coverage')\n",
    "for model in predictions.columns.drop(['Original_Targets']):\n",
    "    accuracies = []\n",
    "    for target in model_accuracies.index:\n",
    "        # Select only the rows corresponding to the current class\n",
    "        subset = predictions[predictions['Original_Targets'] == target]\n",
    "        # Calculate the accuracy as the mean of correct predictions\n",
    "        accuracy = (subset[model] == target).mean()\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    # Assign the computed accuracies to the respective model column\n",
    "    model_accuracies[model] = accuracies\n",
    "\n",
    "lineage_df = pd.concat([model_accuracies, predictions['Original_Targets'].value_counts()], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cedd3aa3-97db-45a7-81ea-a01485452f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the sorted unique lineages as a column\n",
    "expanded_lineages = []\n",
    "for lineage in lineage_df.index:\n",
    "    output = split_and_replace(lineage, mapping)\n",
    "    output_str = \"\".join(output)\n",
    "    expanded_lineages.append(output_str)\n",
    "\n",
    "lineage_df.index = expanded_lineages\n",
    "simple_lineages = lineage_df[~lineage_df.index.astype(str).str.contains(r\"\\[|\\*\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d7768-8d27-4070-8c68-b7346db0d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [item for item in simple_lineages.index if item.count('.') <= 13]\n",
    "split_strings = [s.split('.') + [None] * (13 - s.count('.')) for s in paths]\n",
    "\n",
    "# Creating a DataFrame from the split strings\n",
    "df = pd.DataFrame(split_strings, columns=['Level 1', 'Level 2', 'Level 3', 'Level 4', 'Level 5', 'Level 6', 'Level 7', 'Level 8', 'Level 9', 'Level 10', 'Level 11', 'Level 12', 'Level 13', 'Level 14'])\n",
    "df['Values'] = np.log(simple_lineages[\"count\"].tolist())\n",
    "# df['Values'] = np.ones(len(df))\n",
    "df[\"FFP\"] = simple_lineages[\"FFP\"].tolist()\n",
    "df[\"K-mer\"] = simple_lineages[\"K-mer\"].tolist()\n",
    "df[\"Spaced\"] = simple_lineages[\"Spaced\"].tolist()\n",
    "df[\"ACS\"] = simple_lineages[\"ACS\"].tolist()\n",
    "df[\"GSP\"] = simple_lineages[\"GSP\"].tolist()\n",
    "df[\"FCGR\"] = simple_lineages[\"FCGR\"].tolist()\n",
    "df[\"Mash\"] = simple_lineages[\"Mash\"].tolist()\n",
    "df[\"RTD\"] = simple_lineages[\"RTD\"].tolist()\n",
    "\n",
    "df = add_conflicts(df.copy())\n",
    "df = resolve_conflicts(df.copy())\n",
    "df['Values'] = df.apply(adjust_values, axis=1)\n",
    "\n",
    "features = [\"FFP\", \"K-mer\", \"Spaced\", \"ACS\", \"GSP\", \"FCGR\", \"Mash\", \"RTD\"]\n",
    "num_features = len(features)\n",
    "\n",
    "# Initialize a subplot figure with vertical stacking\n",
    "fig = make_subplots(rows=num_features, cols=1, specs=[[{\"type\": \"domain\"}]] * num_features, vertical_spacing=0)\n",
    "\n",
    "for i, feature in enumerate(features, start=1):\n",
    "    # Update your DataFrame's color based on the feature\n",
    "    df[\"Color\"] = df[feature]\n",
    "\n",
    "    # Create a Plotly Express sunburst figure for each feature\n",
    "    px_fig = px.sunburst(df, path=['Level 1', 'Level 2', 'Level 3', 'Level 4', 'Level 5', 'Level 6', 'Level 7', 'Level 8', 'Level 9', 'Level 10', 'Level 11', 'Level 12', 'Level 13', 'Level 14'], values='Values', color=\"Color\")\n",
    "    \n",
    "    # Extract data for custom control\n",
    "    labels = px_fig['data'][0]['labels'].tolist()\n",
    "    parents = px_fig['data'][0]['parents'].tolist()\n",
    "    values = px_fig['data'][0]['values'].tolist()\n",
    "    ids = px_fig['data'][0]['ids'].tolist()\n",
    "    colors = px_fig.data[0].marker.colors\n",
    "\n",
    "    removes = encode_fullstops(labels)\n",
    "    new_labels = filter_elements(labels, removes)\n",
    "    new_parents = filter_elements(parents, removes)\n",
    "    new_values = filter_elements(values, removes)\n",
    "    new_ids = filter_elements(ids, removes)\n",
    "    new_colors = filter_elements(colors, removes)\n",
    "\n",
    "    # Add the customized sunburst trace to the subplot\n",
    "    fig.add_trace(go.Sunburst(\n",
    "        labels=new_labels,\n",
    "        parents=new_parents,\n",
    "        values=new_values,\n",
    "        ids=new_ids,\n",
    "        branchvalues='total',\n",
    "        insidetextorientation='radial',\n",
    "        marker=dict(\n",
    "            colors=new_colors,  # your color values\n",
    "            colorscale='Blues',\n",
    "            cmin=0,  # setting minimum of color range\n",
    "            cmax=1,  # setting maximum of color range\n",
    "            showscale=(i == num_features)  # Show color scale only on the last plot\n",
    "        )\n",
    "    ), row=i, col=1)\n",
    "\n",
    "# Update layout to fit the stacked sunburst plots without gaps\n",
    "fig.update_layout(\n",
    "    height=1000 * num_features,\n",
    "    width=1000,\n",
    "    margin=dict(t=0, l=0, b=0, r=0)\n",
    ")\n",
    "\n",
    "# Add titles to each subplot\n",
    "for i, feature in enumerate(features, start=1):\n",
    "    fig.add_annotation(\n",
    "        text=feature,  # Subplot title text\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        x=0.5, y=1 - (i - 0.5) / num_features,\n",
    "        xanchor=\"center\", yanchor=\"bottom\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=14)\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CERI)",
   "language": "python",
   "name": "ceri"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
