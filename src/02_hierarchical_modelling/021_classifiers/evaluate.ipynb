{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2efa9a39-6c5f-4b36-9762-54264d24dab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae8c23b4-100c-492a-ac70-86723d21c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_and_store_classes(row):\n",
    "    # Extract columns with positive prediction (value of 1)\n",
    "    columns_with_positive_prediction = [col for col in predictions_df.columns if row[col] == 1]\n",
    "    \n",
    "    \n",
    "    # If there's only one positive prediction, use it as the most specific node\n",
    "    if len(columns_with_positive_prediction) == 0:\n",
    "        return 'None', 'None'\n",
    "    if len(columns_with_positive_prediction) == 1:\n",
    "        most_specific_node = columns_with_positive_prediction[0]\n",
    "        sorted_nodes = [].append(most_specific_node)\n",
    "    else:\n",
    "        # Sort the nodes by depth (count of \".\") and then lexicographically\n",
    "        sorted_nodes = sorted(columns_with_positive_prediction, key=lambda x: (x.count('.'), x), reverse=True)\n",
    "        most_specific_node = sorted_nodes[0]  # Assume the first node is the most specific after sorting\n",
    "    \n",
    "    return most_specific_node, sorted_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6713861d-5414-4e32-9a1e-b62f035a6128",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_policy = \"less_inclusive\"\n",
    "\n",
    "predictions_df = pd.read_csv(f'local_per_node_predictions/LPN_{label_policy}.csv', index_col=0)\n",
    "y_val = pd.read_csv('y_val.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dd858e-782e-4626-a002-f52d04f7f3b9",
   "metadata": {},
   "source": [
    "### Binary Structured Label Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9653703b-9b85-485d-babb-a017c9bce4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_root_children(predictions_df):\n",
    "    # Extract column names that don't contain '.' indicating they are root children\n",
    "    return [col for col in predictions_df.columns if '.' not in col]\n",
    "\n",
    "def get_children(node, predictions_df):\n",
    "    if node:  # If the node is specified, find its children\n",
    "        prefix = node + '.'\n",
    "        return [col for col in predictions_df.columns if col.startswith(prefix) and col.count('.') == node.count('.') + 1]\n",
    "    else:  # If no node is specified, return root children\n",
    "        return get_root_children(predictions_df)\n",
    "\n",
    "\n",
    "def navigate_tree(predictions_df):\n",
    "    results_df = pd.DataFrame(index=predictions_df.index)\n",
    "\n",
    "    for index, row in predictions_df.iterrows():\n",
    "        current_nodes = get_root_children(predictions_df)  # Start with root children\n",
    "        predicted_path = []\n",
    "\n",
    "        while current_nodes:\n",
    "            next_nodes = []\n",
    "            node_found = False\n",
    "            for node in current_nodes:\n",
    "                if row[node] > 0.5:  # Satisfactory confidence level\n",
    "                    predicted_path.append(node)\n",
    "                    node_found = True\n",
    "                    child_nodes = get_children(node, predictions_df)\n",
    "                    next_nodes.extend(child_nodes)\n",
    "\n",
    "            if not node_found:  # No positive classifications at the current level\n",
    "                break\n",
    "\n",
    "            current_nodes = next_nodes\n",
    "\n",
    "        # results_df.at[index, 'Predicted Path'] = ' > '.join(predicted_path)\n",
    "        results_df.at[index, 'prediction'] = predicted_path[-1]\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75f1804d-495e-47e2-87df-11cd461be09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9778103176391079\n",
      "F1 Score: 0.9784948884278595\n"
     ]
    }
   ],
   "source": [
    "y_pred_BSLL = navigate_tree(predictions_df)\n",
    "# Evaluate the overall performance\n",
    "accuracy = accuracy_score(y_val, y_pred_BSLL)\n",
    "f1 = f1_score(y_val, y_pred_BSLL, average='weighted')  # Consider weighted if class imbalance is present\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf9af27d-ced3-43fd-9e32-86290172e204",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_BSLL.to_csv(f'predictions/LPN_{label_policy}_BSLL.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91480f5-6a97-4408-84e4-b9e585ae7a7f",
   "metadata": {},
   "source": [
    "### Multiplicative Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edcad7b1-0e80-408a-bfd0-ec782bf639d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_path(col):\n",
    "    \"\"\"\n",
    "    Derive the class path from the root to the specified column (class).\n",
    "\n",
    "    Parameters:\n",
    "    - col (str): The column name representing the class, formatted in a hierarchical dot notation.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: A list of column names representing the path from the root to the class.\n",
    "    \"\"\"\n",
    "    # Split the column name based on dots to get individual nodes in the path\n",
    "    nodes = col.split('.')\n",
    "\n",
    "    # Initialize an empty list to store the path\n",
    "    class_path = []\n",
    "\n",
    "    # Iterate over the nodes to build the path\n",
    "    for i in range(1, len(nodes) + 1):\n",
    "        # Reconstruct the class name at each level of the hierarchy\n",
    "        class_name = '.'.join(nodes[:i])\n",
    "        class_path.append(class_name)\n",
    "\n",
    "    return class_path\n",
    "\n",
    "def compute_class_path_products(predictions_df):\n",
    "    # Initialize a dictionary to store the intermediate products\n",
    "    products_dict = {}\n",
    "\n",
    "    # Iterate over columns (classifiers) to compute the product of probabilities along the path\n",
    "    for col in predictions_df.columns:\n",
    "        class_path = get_class_path(col)  # Ensure this function is defined and correct\n",
    "        products_dict[col] = predictions_df[class_path].prod(axis=1)\n",
    "\n",
    "    # Create the product DataFrame from the dictionary in one go\n",
    "    product_df = pd.DataFrame(products_dict)\n",
    "\n",
    "    return product_df\n",
    "\n",
    "def select_deepest_classification(product_df, threshold=0.5):\n",
    "    # Apply the threshold\n",
    "    above_threshold = product_df >= threshold\n",
    "\n",
    "    # Sort columns by their depth (assuming deeper nodes have longer names)\n",
    "    sorted_columns = sorted(product_df.columns, key=lambda x: len(x), reverse=True)\n",
    "    sorted_product_df = product_df[sorted_columns]\n",
    "\n",
    "    # Initialize a Series to store the final classification for each observation\n",
    "    final_classifications = pd.Series(index=sorted_product_df.index, dtype=\"object\")\n",
    "\n",
    "    # Iterate over the sorted DataFrame to find the deepest classification\n",
    "    for idx, row in sorted_product_df.iterrows():\n",
    "        for col in sorted_columns:\n",
    "            if row[col] and above_threshold.at[idx, col]:\n",
    "                final_classifications.at[idx] = col\n",
    "                break  # Stop at the deepest valid classification\n",
    "\n",
    "    return final_classifications\n",
    "\n",
    "def apply_multiplicative_rule(predictions_df, threshold=0.5):\n",
    "    product_df = compute_class_path_products(predictions_df)\n",
    "    final_classifications = select_deepest_classification(product_df, threshold)\n",
    "    return final_classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac4654ba-c16c-4b80-a3a9-d4680a378411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds and their corresponding accuracies:\n",
      "Threshold: 0.30, Accuracy: 0.9646\n",
      "Threshold: 0.32, Accuracy: 0.9669\n",
      "Threshold: 0.34, Accuracy: 0.9681\n",
      "Threshold: 0.36, Accuracy: 0.9704\n",
      "Threshold: 0.38, Accuracy: 0.9716\n",
      "Threshold: 0.40, Accuracy: 0.9742\n",
      "Threshold: 0.42, Accuracy: 0.9748\n",
      "Threshold: 0.44, Accuracy: 0.9751\n",
      "Threshold: 0.46, Accuracy: 0.9756\n",
      "Threshold: 0.48, Accuracy: 0.9757\n",
      "Threshold: 0.50, Accuracy: 0.9749\n",
      "Threshold: 0.52, Accuracy: 0.9741\n",
      "Threshold: 0.54, Accuracy: 0.9733\n",
      "Threshold: 0.56, Accuracy: 0.9720\n",
      "Threshold: 0.58, Accuracy: 0.9700\n",
      "Threshold: 0.60, Accuracy: 0.9680\n",
      "Threshold: 0.62, Accuracy: 0.9668\n",
      "Threshold: 0.64, Accuracy: 0.9637\n",
      "Threshold: 0.66, Accuracy: 0.9600\n",
      "Threshold: 0.68, Accuracy: 0.9557\n",
      "\n",
      "Best Threshold: 0.48 with Accuracy: 0.9757\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0.3, 0.7, 0.02)  # 0.8 is included\n",
    "best_accuracy = 0\n",
    "best_threshold = 0\n",
    "\n",
    "print(\"Thresholds and their corresponding accuracies:\")\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_mult = apply_multiplicative_rule(predictions_df, threshold=threshold)\n",
    "    accuracy = accuracy_score(y_val, y_pred_mult)\n",
    "    print(f\"Threshold: {threshold:.2f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"\\nBest Threshold: {best_threshold:.2f} with Accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08904d7c-b7d9-460f-8da2-cee1ddefc28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_mult = apply_multiplicative_rule(predictions_df, threshold=best_threshold)\n",
    "y_pred_mult.to_csv(f'predictions/LPN_{label_policy}_mult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866e0865-9007-48db-8fb1-a29a9f41303e",
   "metadata": {},
   "source": [
    "### Longest Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e9d2a4a-bf90-41c3-9000-b8e413ad09ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to each row and store the results\n",
    "thresholded_df = (predictions_df > 0.5).astype(int)\n",
    "results = thresholded_df.apply(lambda row: determine_and_store_classes(row), axis=1)\n",
    "\n",
    "# Separate the predictions and the sorted lists\n",
    "y_pred_longest = results.apply(lambda x: x[0])\n",
    "sorted_nodes_list = results.apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "575326b7-ee2f-420e-8899-a9d5f34e21b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.977247127731471\n",
      "F1 Score: 0.9778176570733454\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the overall performance\n",
    "accuracy = accuracy_score(y_val, y_pred_longest)\n",
    "f1 = f1_score(y_val, y_pred_longest, average='weighted')  # Consider weighted if class imbalance is present\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e76e4ebc-cf45-4d35-8d92-a5b264c4d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_longest.to_csv(f'predictions/LPN_{label_policy}_longest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cc4e68b-1b21-4e2b-aa7e-aaef72e8b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_val = y_val.reset_index(drop=True)\n",
    "# y_pred_longest = y_pred_longest.reset_index(drop=True)\n",
    "# sorted_nodes_list = sorted_nodes_list.reset_index(drop=True)\n",
    "\n",
    "# mismatches = y_val != y_pred_longest\n",
    "\n",
    "# # Filtering the instances with mismatches\n",
    "# mismatched_targets = y_val[mismatches]\n",
    "# mismatched_predictions = sorted_nodes_list[mismatches]\n",
    "\n",
    "# # Ensure that mismatched_predictions is a list or a Series of lists\n",
    "# if not isinstance(mismatched_predictions.iloc[0], list):\n",
    "#     mismatched_predictions = mismatched_predictions.apply(eval)\n",
    "\n",
    "# # Create the formatted output using a list comprehension\n",
    "# output = [f\"Target: {y}, LC: {pred}\" for y, pred in zip(mismatched_targets, mismatched_predictions)]\n",
    "\n",
    "# # Display the output\n",
    "# for item in output:\n",
    "#     print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
