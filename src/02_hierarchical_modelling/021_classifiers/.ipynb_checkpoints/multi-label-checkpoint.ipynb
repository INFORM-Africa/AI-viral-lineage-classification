{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a4d28f0-e1a0-4930-8db6-1c2568a3b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ff7772f-10aa-406f-bf91-8a3d8fea79fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name, dataset):\n",
    "    \"\"\"\n",
    "    Load the data from a Parquet file, encode the target variable, and split the data into training and validation sets.\n",
    "\n",
    "    Parameters:\n",
    "    - file_name (str): Name of the file to load (without '.parquet' extension and path).\n",
    "\n",
    "    Returns:\n",
    "    - X_train (DataFrame): Training features.\n",
    "    - y_train (Series): Training labels.\n",
    "    - X_val (DataFrame): Validation features.\n",
    "    - y_val (Series): Validation labels.\n",
    "    \"\"\"\n",
    "    data_path = f'../../../data/features/{dataset}/{file_name}.parquet'\n",
    "    data = pd.read_parquet(data_path)\n",
    "    \n",
    "    expanded_lineages = []\n",
    "    for lineage in data[\"Target\"]:\n",
    "        output = split_and_replace(lineage, mapping)\n",
    "        output_str = \"\".join(output)\n",
    "        expanded_lineages.append(output_str)\n",
    "    \n",
    "    data[\"Target\"] = expanded_lineages\n",
    "    data = data[~data[\"Target\"].astype(str).str.contains(r\"\\[|\\*\")]\n",
    "\n",
    "    X_train = data[data['Train'] == 0].drop(columns=[\"Target\", \"Train\"])\n",
    "    y_train = data[data['Train'] == 0]['Target']\n",
    "    X_val = data[data['Train'] == 1].drop(columns=[\"Target\", \"Train\"])\n",
    "    y_val = data[data['Train'] == 1]['Target']\n",
    "\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "def get_root_children(predictions_df):\n",
    "    # Extract column names that don't contain '.' indicating they are root children\n",
    "    return [col for col in predictions_df.columns if '.' not in col]\n",
    "\n",
    "def get_children(node, predictions_df):\n",
    "    if node:  # If the node is specified, find its children\n",
    "        prefix = node + '.'\n",
    "        return [col for col in predictions_df.columns if col.startswith(prefix) and col.count('.') == node.count('.') + 1]\n",
    "    else:  # If no node is specified, return root children\n",
    "        return get_root_children(predictions_df)\n",
    "\n",
    "\n",
    "def navigate_tree(predictions_df):\n",
    "    results_df = pd.DataFrame(index=predictions_df.index)\n",
    "\n",
    "    for index, row in predictions_df.iterrows():\n",
    "        current_nodes = get_root_children(predictions_df)  # Start with root children\n",
    "        predicted_path = []\n",
    "\n",
    "        while current_nodes:\n",
    "            next_nodes = []\n",
    "            node_found = False\n",
    "            for node in current_nodes:\n",
    "                if row[node] > 0.5:  # Satisfactory confidence level\n",
    "                    predicted_path.append(node)\n",
    "                    node_found = True\n",
    "                    child_nodes = get_children(node, predictions_df)\n",
    "                    next_nodes.extend(child_nodes)\n",
    "\n",
    "            if not node_found:  # No positive classifications at the current level\n",
    "                break\n",
    "\n",
    "            current_nodes = next_nodes\n",
    "\n",
    "        # results_df.at[index, 'Predicted Path'] = ' > '.join(predicted_path)\n",
    "        results_df.at[index, 'prediction'] = predicted_path[-1]\n",
    "\n",
    "    return results_df\n",
    "\n",
    "def get_class_path(col):\n",
    "    \"\"\"\n",
    "    Derive the class path from the root to the specified column (class).\n",
    "\n",
    "    Parameters:\n",
    "    - col (str): The column name representing the class, formatted in a hierarchical dot notation.\n",
    "\n",
    "    Returns:\n",
    "    - List[str]: A list of column names representing the path from the root to the class.\n",
    "    \"\"\"\n",
    "    # Split the column name based on dots to get individual nodes in the path\n",
    "    nodes = col.split('.')\n",
    "\n",
    "    # Initialize an empty list to store the path\n",
    "    class_path = []\n",
    "\n",
    "    # Iterate over the nodes to build the path\n",
    "    for i in range(1, len(nodes) + 1):\n",
    "        # Reconstruct the class name at each level of the hierarchy\n",
    "        class_name = '.'.join(nodes[:i])\n",
    "        class_path.append(class_name)\n",
    "\n",
    "    return class_path\n",
    "\n",
    "def compute_class_path_products(predictions_df):\n",
    "    # Initialize a dictionary to store the intermediate products\n",
    "    products_dict = {}\n",
    "\n",
    "    # Iterate over columns (classifiers) to compute the product of probabilities along the path\n",
    "    for col in predictions_df.columns:\n",
    "        class_path = get_class_path(col)  # Ensure this function is defined and correct\n",
    "        products_dict[col] = predictions_df[class_path].prod(axis=1)\n",
    "\n",
    "    # Create the product DataFrame from the dictionary in one go\n",
    "    product_df = pd.DataFrame(products_dict)\n",
    "\n",
    "    return product_df\n",
    "\n",
    "def select_deepest_classification(product_df, threshold=0.5):\n",
    "    # Apply the threshold\n",
    "    above_threshold = product_df >= threshold\n",
    "\n",
    "    # Sort columns by their depth (assuming deeper nodes have longer names)\n",
    "    sorted_columns = sorted(product_df.columns, key=lambda x: len(x), reverse=True)\n",
    "    sorted_product_df = product_df[sorted_columns]\n",
    "\n",
    "    # Initialize a Series to store the final classification for each observation\n",
    "    final_classifications = pd.Series(index=sorted_product_df.index, dtype=\"object\")\n",
    "\n",
    "    # Iterate over the sorted DataFrame to find the deepest classification\n",
    "    for idx, row in sorted_product_df.iterrows():\n",
    "        for col in sorted_columns:\n",
    "            if row[col] and above_threshold.at[idx, col]:\n",
    "                final_classifications.at[idx] = col\n",
    "                break  # Stop at the deepest valid classification\n",
    "\n",
    "    return final_classifications\n",
    "\n",
    "def apply_multiplicative_rule(predictions_df, threshold=0.5):\n",
    "    product_df = compute_class_path_products(predictions_df)\n",
    "    final_classifications = select_deepest_classification(product_df, threshold)\n",
    "    return final_classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64905ea0-4fc6-4fd0-b43b-0989fe939bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string(input_string):\n",
    "    segments = []\n",
    "    current_segment = \"\"\n",
    "\n",
    "    for char in input_string:\n",
    "        if char.isalnum():\n",
    "            current_segment += char  # Append alphanumeric characters to the current segment\n",
    "        elif char.isspace():\n",
    "            continue  # Skip whitespace characters\n",
    "        else:\n",
    "            if current_segment:\n",
    "                segments.append(current_segment)  # Add the current segment to the list\n",
    "                current_segment = \"\"\n",
    "            segments.append(char)  # Add the delimiter as a separate segment\n",
    "\n",
    "    if current_segment:\n",
    "        segments.append(current_segment)  # Add the last segment if any\n",
    "\n",
    "    return segments\n",
    "\n",
    "def split_and_replace(input_string, mapping):\n",
    "    segments = split_string(input_string)\n",
    "    i = 0\n",
    "\n",
    "    while i < len(segments):\n",
    "        segment = segments[i]\n",
    "        if segment in mapping:\n",
    "            # Replace the segment with its mapped value and split it\n",
    "            new_segments = split_string(mapping[segment])\n",
    "            segments = segments[:i] + new_segments + segments[i+1:]\n",
    "            # Do not increment i, so the loop will check the new segments on the next iteration\n",
    "        else:\n",
    "            # Only increment i if no replacement was done\n",
    "            i += 1\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be97f52a-1fe6-4c8b-9b5d-b2250f9cdc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('alias_key.json', 'r') as f:\n",
    "    mapping = json.load(f)\n",
    "\n",
    "for key, value in mapping.items():\n",
    "    if isinstance(value, list):\n",
    "        mapping[key] = '[' + ', '.join(value) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e662c1-5c24-4eac-add9-9e55486258a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = [os.path.splitext(os.path.basename(file))[0] for file in glob.glob(\"../../../data/features/SARS/*.parquet\")]\n",
    "dataset = \"SARS\"\n",
    "file_name = \"FCGR_remove_256\"\n",
    "# print(file_names)\n",
    "\n",
    "X_train, y_train, X_val, y_val = load_data(file_name, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97ef2838-f77e-4ee4-884b-2a741117ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_labels(labels):\n",
    "    expanded_labels = []\n",
    "    for label in labels:\n",
    "        parts = label.split('.')\n",
    "        ancestors = ['.'.join(parts[:i+1]) for i in range(len(parts))]\n",
    "        expanded_labels.append(ancestors)\n",
    "    return expanded_labels\n",
    "\n",
    "y_train_expanded = expand_labels(y_train)\n",
    "y_val_expanded = expand_labels(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "078ec928-ee48-4030-80b6-94bfc530dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train_mlb = mlb.fit_transform(y_train_expanded)\n",
    "y_val_mlb = mlb.transform(y_val_expanded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05306d3a-8779-457a-83b3-5b292bff76e6",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "823e3528-bb49-4554-9f67-7e5a3560fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf.fit(X_train, y_train_mlb)\n",
    "\n",
    "# Predict on the test data\n",
    "y_prob_mlb = rf.predict_proba(X_val)\n",
    "\n",
    "# Extracting the positive class probabilities for each class\n",
    "confidences = np.array(y_prob_mlb)[:, :, 1].T\n",
    "\n",
    "confidences_df = pd.DataFrame(confidences, columns=mlb.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9123c87f-35fe-4988-b248-7dd7d56c757f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.975107006082451\n",
      "F1 Score: 0.975827162992359\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf_BSLL = navigate_tree(confidences_df)\n",
    "# Evaluate the overall performance\n",
    "accuracy = accuracy_score(y_val, y_pred_rf_BSLL)\n",
    "f1 = f1_score(y_val, y_pred_rf_BSLL, average='weighted')  # Consider weighted if class imbalance is present\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "y_pred_rf_BSLL.to_csv('predictions/multi-label_random_forest_BSLL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e77a5d87-7cfa-4872-8745-43505d6d2628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholds and their corresponding accuracies:\n",
      "Threshold: 0.30, Accuracy: 0.9674\n",
      "Threshold: 0.32, Accuracy: 0.9683\n",
      "Threshold: 0.34, Accuracy: 0.9696\n",
      "Threshold: 0.36, Accuracy: 0.9705\n",
      "Threshold: 0.38, Accuracy: 0.9716\n",
      "Threshold: 0.40, Accuracy: 0.9715\n",
      "Threshold: 0.42, Accuracy: 0.9721\n",
      "Threshold: 0.44, Accuracy: 0.9727\n",
      "Threshold: 0.46, Accuracy: 0.9729\n",
      "Threshold: 0.48, Accuracy: 0.9725\n",
      "Threshold: 0.50, Accuracy: 0.9718\n",
      "Threshold: 0.52, Accuracy: 0.9709\n",
      "Threshold: 0.54, Accuracy: 0.9691\n",
      "Threshold: 0.56, Accuracy: 0.9674\n",
      "Threshold: 0.58, Accuracy: 0.9655\n",
      "Threshold: 0.60, Accuracy: 0.9628\n",
      "Threshold: 0.62, Accuracy: 0.9590\n",
      "Threshold: 0.64, Accuracy: 0.9555\n",
      "Threshold: 0.66, Accuracy: 0.9503\n",
      "Threshold: 0.68, Accuracy: 0.9454\n",
      "\n",
      "Best Threshold: 0.46 with Accuracy: 0.9729\n"
     ]
    }
   ],
   "source": [
    "thresholds = np.arange(0.3, 0.7, 0.02)  # 0.8 is included\n",
    "best_accuracy = 0\n",
    "best_threshold = 0\n",
    "\n",
    "print(\"Thresholds and their corresponding accuracies:\")\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_mult = apply_multiplicative_rule(confidences_df, threshold=threshold)\n",
    "    accuracy = accuracy_score(y_val, y_pred_mult)\n",
    "    print(f\"Threshold: {threshold:.2f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"\\nBest Threshold: {best_threshold:.2f} with Accuracy: {best_accuracy:.4f}\")\n",
    "y_pred_rf_mult = apply_multiplicative_rule(confidences_df, threshold=best_threshold)\n",
    "y_pred_rf_mult.to_csv('predictions/multi-label_random_forest_mult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837a903c-d4bb-47fa-a7cb-fd33b620c57d",
   "metadata": {},
   "source": [
    "### Binary Relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89ccc468-de96-4929-9e26-45d5e65ec812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "\n",
    "# Initialize the RandomForest classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Wrap the classifier with MultiOutputClassifier which suits for the binary relevance method\n",
    "multi_target_classifier = MultiOutputClassifier(classifier, n_jobs=-1)\n",
    "\n",
    "# Fit the model on the multi-label transformed training data\n",
    "multi_target_classifier.fit(X_train, y_train_mlb)\n",
    "\n",
    "# Predict on the test data\n",
    "y_prob_mlb = multi_target_classifier.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ff136b1-acd8-46b7-92e9-a7a62b3081dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9782608695652174\n",
      "F1 Score: 0.9789409060351784\n",
      "Thresholds and their corresponding accuracies:\n",
      "Threshold: 0.30, Accuracy: 0.9699\n",
      "Threshold: 0.32, Accuracy: 0.9713\n",
      "Threshold: 0.34, Accuracy: 0.9724\n",
      "Threshold: 0.36, Accuracy: 0.9729\n",
      "Threshold: 0.38, Accuracy: 0.9743\n",
      "Threshold: 0.40, Accuracy: 0.9763\n",
      "Threshold: 0.42, Accuracy: 0.9767\n",
      "Threshold: 0.44, Accuracy: 0.9762\n",
      "Threshold: 0.46, Accuracy: 0.9765\n",
      "Threshold: 0.48, Accuracy: 0.9763\n",
      "Threshold: 0.50, Accuracy: 0.9754\n",
      "Threshold: 0.52, Accuracy: 0.9745\n",
      "Threshold: 0.54, Accuracy: 0.9739\n",
      "Threshold: 0.56, Accuracy: 0.9721\n",
      "Threshold: 0.58, Accuracy: 0.9704\n",
      "Threshold: 0.60, Accuracy: 0.9680\n",
      "Threshold: 0.62, Accuracy: 0.9668\n",
      "Threshold: 0.64, Accuracy: 0.9637\n",
      "Threshold: 0.66, Accuracy: 0.9602\n",
      "Threshold: 0.68, Accuracy: 0.9569\n",
      "\n",
      "Best Threshold: 0.42 with Accuracy: 0.9767\n"
     ]
    }
   ],
   "source": [
    "# Extracting the positive class probabilities for each class\n",
    "confidences = np.array(y_prob_mlb)[:, :, 1].T\n",
    "\n",
    "confidences_df = pd.DataFrame(confidences, columns=mlb.classes_)\n",
    "\n",
    "y_pred_rf_BSLL = navigate_tree(confidences_df)\n",
    "# Evaluate the overall performance\n",
    "accuracy = accuracy_score(y_val, y_pred_rf_BSLL)\n",
    "f1 = f1_score(y_val, y_pred_rf_BSLL, average='weighted')  # Consider weighted if class imbalance is present\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "y_pred_rf_BSLL.to_csv('predictions/multi-label_binary_relevance_BSLL.csv')\n",
    "\n",
    "thresholds = np.arange(0.3, 0.7, 0.02)  # 0.8 is included\n",
    "best_accuracy = 0\n",
    "best_threshold = 0\n",
    "\n",
    "print(\"Thresholds and their corresponding accuracies:\")\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_mult = apply_multiplicative_rule(confidences_df, threshold=threshold)\n",
    "    accuracy = accuracy_score(y_val, y_pred_mult)\n",
    "    print(f\"Threshold: {threshold:.2f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"\\nBest Threshold: {best_threshold:.2f} with Accuracy: {best_accuracy:.4f}\")\n",
    "y_pred_rf_mult = apply_multiplicative_rule(confidences_df, threshold=best_threshold)\n",
    "y_pred_rf_mult.to_csv('predictions/multi-label_binary_relevance_mult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d46d07a-a8ae-44b9-9443-bd4b45532b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.metrics import accuracy_score, hamming_loss\n",
    "\n",
    "# Initialize the base classifier\n",
    "base_classifier = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Creating a Classifier Chain with random order\n",
    "chain = ClassifierChain(base_classifier, order='random', random_state=42)\n",
    "\n",
    "# Fit the Classifier Chain model on the multi-label transformed training data\n",
    "chain.fit(X_train, y_train_mlb)\n",
    "\n",
    "# Predict on the test set\n",
    "y_prob_mlb = chain.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d041f92-8812-4498-82a7-0082941c5b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_mlb =  chain.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d2454e0-9735-4539-ae24-13b9b765a10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 1.  , 0.97, ..., 0.  , 0.02, 0.  ],\n",
       "       [0.  , 0.99, 1.  , ..., 0.  , 0.01, 0.  ],\n",
       "       [0.  , 1.  , 1.  , ..., 0.  , 0.  , 0.  ],\n",
       "       ...,\n",
       "       [0.  , 1.  , 1.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 1.  , ..., 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 1.  , ..., 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob_mlb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3fa0a36-8e46-4504-aada-bf35a9bc23c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9765712998423068\n",
      "F1 Score: 0.9774655423367556\n",
      "Thresholds and their corresponding accuracies:\n",
      "Threshold: 0.30, Accuracy: 0.9697\n",
      "Threshold: 0.32, Accuracy: 0.9704\n",
      "Threshold: 0.34, Accuracy: 0.9718\n",
      "Threshold: 0.36, Accuracy: 0.9731\n",
      "Threshold: 0.38, Accuracy: 0.9743\n",
      "Threshold: 0.40, Accuracy: 0.9750\n",
      "Threshold: 0.42, Accuracy: 0.9753\n",
      "Threshold: 0.44, Accuracy: 0.9752\n",
      "Threshold: 0.46, Accuracy: 0.9743\n",
      "Threshold: 0.48, Accuracy: 0.9745\n",
      "Threshold: 0.50, Accuracy: 0.9744\n",
      "Threshold: 0.52, Accuracy: 0.9740\n",
      "Threshold: 0.54, Accuracy: 0.9734\n",
      "Threshold: 0.56, Accuracy: 0.9725\n",
      "Threshold: 0.58, Accuracy: 0.9707\n",
      "Threshold: 0.60, Accuracy: 0.9692\n",
      "Threshold: 0.62, Accuracy: 0.9674\n",
      "Threshold: 0.64, Accuracy: 0.9642\n",
      "Threshold: 0.66, Accuracy: 0.9607\n",
      "Threshold: 0.68, Accuracy: 0.9564\n",
      "\n",
      "Best Threshold: 0.42 with Accuracy: 0.9753\n"
     ]
    }
   ],
   "source": [
    "# Extracting the positive class probabilities for each class\n",
    "confidences = y_prob_mlb\n",
    "\n",
    "confidences_df = pd.DataFrame(confidences, columns=mlb.classes_)\n",
    "\n",
    "y_pred_rf_BSLL = navigate_tree(confidences_df)\n",
    "# Evaluate the overall performance\n",
    "accuracy = accuracy_score(y_val, y_pred_rf_BSLL)\n",
    "f1 = f1_score(y_val, y_pred_rf_BSLL, average='weighted')  # Consider weighted if class imbalance is present\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "y_pred_rf_BSLL.to_csv('predictions/multi-label_classifier_chain_BSLL.csv')\n",
    "\n",
    "thresholds = np.arange(0.3, 0.7, 0.02)  # 0.8 is included\n",
    "best_accuracy = 0\n",
    "best_threshold = 0\n",
    "\n",
    "print(\"Thresholds and their corresponding accuracies:\")\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_mult = apply_multiplicative_rule(confidences_df, threshold=threshold)\n",
    "    accuracy = accuracy_score(y_val, y_pred_mult)\n",
    "    print(f\"Threshold: {threshold:.2f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"\\nBest Threshold: {best_threshold:.2f} with Accuracy: {best_accuracy:.4f}\")\n",
    "y_pred_rf_mult = apply_multiplicative_rule(confidences_df, threshold=best_threshold)\n",
    "y_pred_rf_mult.to_csv('predictions/multi-label_classifier_chain_mult.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
